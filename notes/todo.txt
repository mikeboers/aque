- tasks should enforce host requirements
  - parse ifconfig via r'inet (addr:)?(\d+\.\d+\.\d+\.\d+)'
  - parse /etc/hosts looking for all synonyms
  - be able to match network masks, e.g. 127.0.0.0/24

- logging in subprocesses should be put through to a special pipe, or perhaps
  through a socket of some sort
  - the logs should be attributes of workers, jobs, queues, brokers, etc, and
    those ones should be modified so they pipe back to their counterparts
    and then don't go further up the chain. This will allow existing logging
    to actually work

- preserve environment for xargs; it seems really inefficient to do it the
  same way as for submit as it would be stuffed onto every task. perhaps
  if isinstance(environ, int) then it can pull the environment from there?

- is there a way of detecting what the mount point is for various io_paths and
  making sure that it corresponds?

- write a test that makes sure that multiple workers run a given task
  only once
    change what the timeouts are heartbeats are for this test so that we
    can simulate

- deploy onto main servers (via AQUE_BROKER="$(ficonfig get aque_broker)")
  - fix permissions; everyone is --superuser so far
  âˆš hk
  - nt
  - ex

- `aque worker --reload` uses metatools reloader (or change detection and
  a restart via os.exec-ing back to itself)

- `killall -HUP aque-worker` -> it execs to itself
  - can I set it's name to aque-worker after it has started, or should I
    actually make various aque-* commands?

- worker should listen to "task_status.pending" to pick up new tasks
  - make it take over the event loop, and just bind something meaningless to
    task_status.pending

- add stdin, stdout, stderr, but should I also have stdin_value,
  somehow encode that into the same field, or just don't have that capability?

- Document (in hacking notes) that I should have the task be relatively flat, and keep the
  pickled things as seperate from each other as possible. We will build
  more flexibility in as required by making the pattern into a class and
  having a bunch of hooks on it for various things.

  Keeping the pickled things seperate allows us to use the least invasive
  pickling that is possible, and keep depickling errors as isolated as possible.

  At most I will consider having an "extra" field which is everything left
  over that gets pickled.

- `aque status --watch` for top-like output

- enumerate all of the states:
    - creating
    - pending
    - cancelled
    - running (I don't know if this would actually exist though)
    - success
    - error

    - creqte aque.states with sets of the above:
        READY_STATES
        UNREADY_STATES
        COMPLETE_STATES

- shell patterns should automatically add IO hints for any arguments that appear to be paths
    - add the longest subpath which exists (even just '/') to the set
    - sum up the size of fully-specified files for a pseudo "duration"

  SOLUTION: only allow functions/classes that can be resolved by name, and
  encode them into our format first

- aque-kill should kill a task
    - `aque-kill -r` would kill all dependencies

- send "task_status" -> "running" when a task starts executing
    or a task_heartbeat with the ID

- workers should respond to priority hints:
    - e.g. hints={'paths': [...], 'duration': 100}
    - 'io_hints' is a sequence of paths that may have IO
    - 'rel_duration' is a float relative to other durations of the same priority,
       and we prioritize longer processes of the same priority

- document relationships of queues, brokers, task prototypes, and futures.
