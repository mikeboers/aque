- worker should be able to schedule a listener on the broker for when there
  are new tasks so that it can immediately wake up

- fork before running tasks
- do we need a Broker.post_fork() to make sure redis is okay?

- If we started using postgresql, what would we store there?
    - most of the task data as it is in a "task" table
    - "func", "args", "kwargs", etc. would be serialized into a "package" field
      OR have actual fields knowing that any other package data could be crammed
      into there for a custom pattern
    - dependencies via association table:
      CREATE TABLE dependency (
        id INTEGER PRIMARY KEY,
        parent_id INTEGER FOREIGN KEY (task.id),
        child_id INTEGER FOREIGN KEY (task.id),
      );
    - logs would go into a logs table
    - status changes, results, exceptions would still get published via redis
    - broker would need to abstract more of the API, and try to not expose
      get/getall/set/setmany fields (although it could)
    - would we want to use postgres directly, or via sqlalchemy?

- document relationships of queues, brokers, task prototypes, and futures.


Distant Future
--------------
- consider migrating to RabbitMQ
