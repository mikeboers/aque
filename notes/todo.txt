
- run as actual user (if root)

- deploy onto main servers (via AQUE_BROKER="$(ficonfig get aque_broker)")

- `aque worker --reload` uses metatools reloader (or change detection and
  a restart via os.exec-ing back to itself)

- `killall -HUP aque-worker` -> it execs to itself
  - can I set it's name to aque-worker after it has started, or should I
    actually make various aque-* commands?

- need to get much more efficient when looking at thousands of tasks
  - if it is a requirement of every broker that it is able to signal when
    there is a status change in a process, then we are able to have the worker
    only listen to that for updates (after fetching the main list, of course)
  - broker.iter_tasks(where={'status': 'pending'}, fields=['id', 'dependencies'])
  - worker keeps a cache of tasks that it has requested, so that it only needs
    to hit the broker for those that it hasn't already seen

- `aque kill <tid>` -> sends an event that the worker hears, and then kills
  the subprocess

- broker should have a standard event listening interface. Take a look at the
  blinker API and see if we should replicate that with Postgres.

- aque xargs only needs to support -P (for parallelism) and -L (for lines)

  - "-P" should set the CPU reservation to "/<value>" (or similar) to indicate
    that we want to reserve a fraction of the total. Should do it this way
    instead of on the submitter because the submitter may not have a matching
    number of processors.

- add stdin, stdout, stderr, but should I also have stdin_value,
  somehow encode that into the same field, or just don't have that capability?

- Document (in hacking notes) that I should have the task be relatively flat, and keep the
  pickled things as seperate from each other as possible. We will build
  more flexibility in as required by making the pattern into a class and
  having a bunch of hooks on it for various things.

  Keeping the pickled things seperate allows us to use the least invasive
  pickling that is possible, and keep depickling errors as isolated as possible.

  At most I will consider having an "extra" field which is everything left
  over that gets pickled.

- `aque status --watch` for top-like output

- enumerate all of the states:
    - creating
    - pending
    - cancelled
    - running (I don't know if this would actually exist though)
    - success
    - error

    - creqte aque.states with sets of the above:
        READY_STATES
        UNREADY_STATES
        COMPLETE_STATES

- shell patterns should automatically add IO hints for any arguments that appear to be paths
    - add the longest subpath which exists (even just '/') to the set
    - sum up the size of fully-specified files for a pseudo "duration"

  SOLUTION: only allow functions/classes that can be resolved by name, and
  encode them into our format first

- task['interpreter'] should be able to set which interpreter we use
  (which is why qbfutures has sandbox.the_corner to work in)
    - need Broker.to_url to pass via AQUE_BROKER

- aque-xargs should match as much of xargs as we need
- aque-kill should kill a task
    - `aque-kill -r` would kill all dependencies

- send "task_status" -> "running" when a task starts executing
    or a task_heartbeat with the ID

- workers should respond to priority hints:
    - e.g. hints={'paths': [...], 'duration': 100}
    - 'io_hints' is a sequence of paths that may have IO
    - 'rel_duration' is a float relative to other durations of the same priority,
       and we prioritize longer processes of the same priority

- reconsider adding children to the graph. They could be exactly the same as
  dependencies, except that they inherit from their parent.

  - children should not be under their parent as far as priority is concerned
    as that will introduce inefficiencies for our IO prioritization

  - it seems the tough problem is mostly determining how to present tasks
    in the Web UI.

- worker should be able to schedule a listener on the broker for when there
  are new tasks so that it can immediately wake up

    broker.register_worker(self)
        - store it in a weakref dict
    broker will then call worker.wake_for_work() when there is new pending work

- document relationships of queues, brokers, task prototypes, and futures.
