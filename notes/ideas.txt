How to prioritize
=================

When we start, subscribe to the "$base@$db:status_changes" queue, then pull all existing pending tasks.

As new tasks are posted (or on start), calculate their invariant scores, and hold them. Consider setting these scores into "$base:task:$jid:scores" so that others can see

Whenever there is a new task, or one finishes, or a pending one will timeout, or HUP, iterate from top to bottom of local list and take the first one that we satisfy the requirements of. This task capture must be atomic.

Each task has a timeout (default to 300 seconds) that allows others to take it over in case it failed. The worker can ping redis periodically (about every half of that time) to assert that the task is still alive.

Priority is per-level only. E.g. astronomical priorities in a sub-task do not affect the scheduling of their parent.


Atomic Captures
===============

Idea 1: "$base:task:$jid:capture_id" is an int of capture attempts. You INCR this then compare to the value in "$base:task:$jid"."capture_id". If the new ID is only one more than the one in the hash, then you won it. You have only a few seconds to update the task and set a "last_active" time.

Idea 2: "$base:task:$jid:lock" is set to when it was locked by its worker. This is set via "SET <key> <worker>:<time> NX EX <timeout>". Unlock with a basic lua script. See: http://redis.io/commands/set


Timeouts
========

The times of the two servers must be accurate. Call redis.time and use that to figure out an offet to our own time so that they are roughly in sync.


Curator & Web UI
================

A curator process removes all logs from redis, and stores tasks once they are done.

"$base:curator" is a hash of info for contacting the curator
    "host" and "port"


Logs are published to "$base:curator_channel", and pushed to "$base:curator_queue" if there wasn't anyone listening to it.

One captures all logs, and stores details of complete tasks once they are done.

- log data chunks are appended to "$base:task:$jid:output" and published to a queue
- chunk format: "<timestamp> <channel> <data>"
- common channels are: stdout, stderr, status, progress, pylogging, usage
- "stdout" and "stderr" channels have format "<index in bytes> data"
- "pylogging" is Python logging
- "usage" is periodic cpu and memory usage, IO counts, etc..
    - stdlib resource and os.times could be helpful
    - psutil could be super helpful https://code.google.com/p/psutil/

- these are dumped to a log file with data 'string-escape'd.

- http api for retrieving old data and logs
    /task/$jid
    /task/$jid/logs


Heirarchy
=========

Stuff like "requirements" are inherited by children if not specified. Then one can make a set of ranges of subtasks and not have to specify that stuff a bajillion times. Perhaps an "inherit=False" could stop that.


Name
====

- rediqueue
- rediq
- pyq "pike"
- quey "queue-y"
- AQuey (ah-kway)
- AQue
- YaQ (Yet Another Queue)
- Yak (Yet Another Kueue)

Statuses
========

"pending" -> task has not run yet

"paused" -> task had not run, and should not run

"success" -> task has run and results may be in "result"

"error" -> task errored and some of the following may be set:
    - "error" -> a message
    - "error_type" -> a class name
    - "exception" -> an exception


API
===

from aque import current_task
current_task() -> proxies to the current task via threading.local()


Testing
=======

For now use the synchonous API. Later figure out how to do it on Redis.


Unsorted
========

- rename Task -> Task?

- task.log -> logger
- func -> target for compatibility with threading/multiprocessing, or "fn" for compatibility with futures?
  if first arg of a Task is callable, then it is the func

- does task.error() raise an exception?

- add "class" to task to specify the Python class; is "type" and "class" then confusing?
  - names for the handler:
    - type (too generic)
    - handler
    - processor
    - prototype
    - dispatcher
    - pattern
    - executor
  - names for the Python class:
    - class
    - type (too generic)
    - constructor
  - best selection: "pattern" and "class"


- "args" value of "children" assembles args from results of children, and "dependencies" is similar
    - same as: func(*(child.result() for child in self.children))

- task.__getitem__ could eval 'attr.func' and 'attr.expr' before looking for 'attr'

- Task class abstracts away all of the storage:

    Task._field_types = dict(
        func='callable',
        etc.
    )

    task[name] -> underlying dict-style store
    task.attr(name) -> "{attr}_func" gets called or "{attr}_expr" gets evaluated
    
    # Sync and async API.
    task.complete(result)
    task.error(message or exception)
    task.children() -> list of Tasks

    # For async handlers only.
    task.progress(count, max=None, message=None)
    task.ping(): this task is still running; don't reschedule it

    # For async schedulers.
    task.cancel()
    task.retry(recursive=False)


- task type is just a callable that takes a Task, registered via entrypoints

    The successful completion of the callable does not signal success because it could be used to schedule a background process. Raising an exception does, however, signal an error.

- "children" are subtasks, while "dependencies" are others parts of a pipeline

- local, syncronous execution first makes sure the dependencies are good, then
  it's children, then itself












- different queuing/flow methods to join up various tasks
    - pipe has results flow from one to the next
    - reduce calls the task once for every dependant result

- `aque` command-line to queue shell tasks
    - output specifies dependency for piping, e.g.:
        a=$(aque echo hello)
        b=$(aque --pipe-from "$a" md5)
        aque --wait --results "$b"

- "groups" or "child templates" allow to have tasks inherit from a template (to ease specification of hundreds of similar tasks)

- perhaps every key should be stored in it's full form (with "$base:task:$jid") so that is is easy to recursively remove a task




- it would be totally OK to do this with Postgres!

- tools to look at with significant startup overhead:
    - REDline
    - ARC_CMD (Arri debayering)
    - one of Jon's image processing scripts, e.g.:
        ~/dev/fidata/hk_dpx_jsrenderpull.py dpxrender_VFX_PULL_030_090913.js | xargs -L24 -P30 ~/dev/fidata/scaler/hk_render_jsdpx.py -j dpxrender_VFX_PULL_030_090913.js


- hkmp1 can git the hk1 redis server, and it is likely that the NT MacPros can do the same

- see http://python-rq.org/

- see https://github.com/percolate/redset

- tasks should be able to specify subtasks without actually creating the objects, to simplify stuff such as chunking ranges of timecodes, etc. However, this doesn't make a ton of sense since each subtask will need to have a status in the end. Ergo, the simplest way is for the caller to manually chunk the task as it is specified. But how then can we get seperate statuses for each of the frames? We could do a map-reduce style arangement...

- Go with a whole map-reduce concept for the whole thing? Each task is a map, and each level performs a reduce. Per-frame errors could be propigated all the way to the top level in a format such that when it is restarted, it is ok.

- Different ways of specifying children:
    - there is a "$base:task:$jid:child_ids" list of child task IDs
    - "range": there is a "range_spec" key on the task
    - "argset": there is a "$base:task:$jid:child_args" list of arguments for children

- Python and bash APIs for fetching info about the current task. Communicated via environment variables.

    current_task().top_level.description
    current_task().set_status('suspend')

- "python_eval" type could have "py_setup", "py_main" and "py_teardown",
  all of which run in the same locals, and have the task spec as the globals. Then
  if you specify a list of locals, it can walk across them all processing them, and
  updating the status of each child

- tasks/subtasks/subsubtasks are traversed in a depth-first manner, and an upper tier may only be captured by a worker if all of the children are complete

- is it possible to have this implemented in a manner so that there isn't a
  master server, but instead it is ALL through redis?

- have a concurrent.futures interface as well

- priority should have several weights: availible memory and processors (drop to zero if the resources don't exist or starting this task would pull us down past zero), if inputs or outputs lie on the direct RAID or across the NFS (weighted inversely by speed?)

    - priority calculators could be discovered via entrypoints. could expose lua fragments that
      are concatted together
    
    - when looking for new work, get the whole pending list and calculate the
      scores for whichever ones are NOT in the worker

- subtasks specified directly, or via ranges

- this would be tons easier if we had the "scan" command

- "$base:task:$jid:children" vs "$base:task.children:$jid"

- reporting by timecodes and durations, instead of individual tasks. Then we can do an output status per sequence.
- ARC_CMD and others may stuff some metadata into the headers such as how many frames were processed in that sequence

- the only non-basic stuff that Jon wants is progress output for both UI updates (e.g. the web UI) and for knowing how far we got if it errored out

- Jon wants to make a modelling tool for each command that predicts what sort of output you will get and check that against what it actually does.

- hook onto Python logging

- the worker will need to run as root


