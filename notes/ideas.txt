How to prioritize
=================

When we start, subscribe to the "$base@$db:status_changes" queue, then pull all existing pending tasks.

As new tasks are posted (or on start), calculate their invariant scores, and hold them. Consider setting these scores into "$base:task:$jid:scores" so that others can see

Whenever there is a new task, or one finishes, or a pending one will timeout, or HUP, iterate from top to bottom of local list and take the first one that we satisfy the requirements of. This task capture must be atomic.

Each task has a timeout (default to 300 seconds) that allows others to take it over in case it failed. The worker can ping redis periodically (about every half of that time) to assert that the task is still alive.

Priority is per-level only. E.g. astronomical priorities in a sub-task do not affect the scheduling of their parent.


Atomic Captures
===============

Idea 1: "$base:task:$jid:capture_id" is an int of capture attempts. You INCR this then compare to the value in "$base:task:$jid"."capture_id". If the new ID is only one more than the one in the hash, then you won it. You have only a few seconds to update the task and set a "last_active" time.

Idea 2: "$base:task:$jid:lock" is set to when it was locked by its worker. This is set via "SET <key> <worker>:<time> NX EX <timeout>". Unlock with a basic lua script. See: http://redis.io/commands/set


Timeouts
========

The times of the two servers must be accurate. Call redis.time and use that to figure out an offet to our own time so that they are roughly in sync.


Curator & Web UI
================

A curator process removes all logs from redis, and stores tasks once they are done.

"$base:curator" is a hash of info for contacting the curator
    "host" and "port"


Logs are published to "$base:curator_channel", and pushed to "$base:curator_queue" if there wasn't anyone listening to it.

One captures all logs, and stores details of complete tasks once they are done.

- log data chunks are appended to "$base:task:$jid:output" and published to a queue
- chunk format: "<timestamp> <channel> <data>"
- common channels are: stdout, stderr, status, progress, pylogging, usage
- "stdout" and "stderr" channels have format "<index in bytes> data"
- "pylogging" is Python logging
- "usage" is periodic cpu and memory usage, IO counts, etc..
    - stdlib resource and os.times could be helpful
    - psutil could be super helpful https://code.google.com/p/psutil/

- these are dumped to a log file with data 'string-escape'd.

- http api for retrieving old data and logs
    /task/$jid
    /task/$jid/logs


Heirarchy
=========

Stuff like "requirements" are inherited by children if not specified. Then one can make a set of ranges of subtasks and not have to specify that stuff a bajillion times. Perhaps an "inherit=False" could stop that.


Name
====

- rediqueue
- rediq
- pyq "pike"
- quey "queue-y"
- AQuey (ah-kway)
- AQue
- YaQ (Yet Another Queue)
- Yak (Yet Another Kueue)

Statuses
========

"pending" -> task has not run yet

"paused" -> task had not run, and should not run

"success" -> task has run and results may be in "result"

"error" -> task errored and some of the following may be set:
    - "error" -> a message
    - "error_type" -> a class name
    - "exception" -> an exception


API
===

from aque import current_task
current_task() -> proxies to the current task via threading.local()


Testing
=======

For now use the synchonous API. Later figure out how to do it on Redis.


Unsorted
========


- once a Task has been frozen, do not allow changes to it from the user's side

    - everything which gets stored must have a task property to serialize it
    - this can deny changes one task.is_frozen

- task.args():
    - self['args'] == 'children' assembles args from results of children
    - self['args'] == 'dependencies' is similar

- task.__getitem__ could eval 'attr.func' and 'attr.expr' before looking for 'attr'

- task.lookup(name, eval=True, walk=True)
    - lookup a name in this task, then the parent, all the way to the top

- Task.cast(input_)

- task.backrefs = set()
    - set of Tasks which list this as a child or dependency
    - could be built by .freeze(), or similar

- Task class abstracts away all of the storage:

    Task._field_types = dict(
        func='callable',
        etc.
    )

    task[name] -> underlying dict-style store
    
    # Sync and async API.
    task.complete(result)
    task.error(message or exception)

    task.children() -> list of Tasks
    task.dependencies() -> list of Tasks

    # For async patterns only.
    task.progress(count, max=None, message=None)
    task.ping(): this task is still running; don't reschedule it

    # For async schedulers.
    task.cancel()
    task.retry(recursive=False)

- `aque` command-line to queue shell tasks
    - output specifies dependency for piping, e.g.:
        a=$(aque echo hello)
        b=$(aque --pipe-from "$a" md5)
        aque --wait --results "$b"

- "groups" or "child templates" allow to have tasks inherit from a template (to ease specification of hundreds of similar tasks)
    TaskTemplate() -> does not actually run, and modifies the returned children.

- tools to look at with significant startup overhead:
    - REDline
    - ARC_CMD (Arri debayering)
    - one of Jon's image processing scripts, e.g.:
        ~/dev/fidata/hk_dpx_jsrenderpull.py dpxrender_VFX_PULL_030_090913.js | xargs -L24 -P30 ~/dev/fidata/scaler/hk_render_jsdpx.py -j dpxrender_VFX_PULL_030_090913.js

- Different ways of specifying children:
    - a list of child IDs
    - "range": there is a "range_spec" key on the task

- Python and bash APIs for fetching info about the current task. Communicated via environment variables.

    current_task().top_level.description
    current_task().set_status('suspend')

- "python_eval" type could have "py_setup", "py_main" and "py_teardown",
  all of which run in the same locals, and have the task spec as the globals. Then
  if you specify a list of locals, it can walk across them all processing them, and
  updating the status of each child

- tasks/subtasks/subsubtasks are traversed in a depth-first manner, and an upper tier may only be captured by a worker if all of the children are complete

- is it possible to have this implemented in a manner so that there isn't a
  master server, but instead it is ALL through redis?

- have a concurrent.futures interface as well

- priority should have several weights: availible memory and processors (drop to zero if the resources don't exist or starting this task would pull us down past zero), if inputs or outputs lie on the direct RAID or across the NFS (weighted inversely by speed?)

    - priority calculators could be discovered via entrypoints. could expose lua fragments that
      are concatted together
    
    - when looking for new work, get the whole pending list and calculate the
      scores for whichever ones are NOT in the worker

- subtasks specified directly, or via ranges

- this would be tons easier if we had the "scan" command

- "$base:task:$jid:children" vs "$base:task.children:$jid"

- reporting by timecodes and durations, instead of individual tasks. Then we can do an output status per sequence.
- ARC_CMD and others may stuff some metadata into the headers such as how many frames were processed in that sequence

- the only non-basic stuff that Jon wants is progress output for both UI updates (e.g. the web UI) and for knowing how far we got if it errored out

- Jon wants to make a modelling tool for each command that predicts what sort of output you will get and check that against what it actually does.

- hook onto Python logging

- the worker will need to run as root

- `default` for json.dumps to look for __aque_reduce__ for custom serializations
    - eventually returns '!!aque/reduced {}'.format(json.dumps(obj.__aque_reduce__))
    - or returns {'!!': type, ...} or
    - these are yaml-style tags, and look somewhat like shebangs

- Task should be a wrapper around a dict instead of a subclass. Then it can
  set the store to None when only given an ID, and load it all via Redis when
  requested later.

- task.freeze() -> dict with everything encoded via the schema
- Task.cast(x)

