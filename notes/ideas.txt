logs and resource usage
-----------------------

- log data chunks are appended to "$base:task:$jid:output" and published to a queue
- chunk format: "<timestamp> <channel> <data>"
- common channels are: stdout, stderr, status, progress, pylogging, usage
- "stdout" and "stderr" channels have format "<index in bytes> data"
- "pylogging" is Python logging
- "usage" is periodic cpu and memory usage, IO counts, etc..
    - stdlib resource and os.times could be helpful
    - psutil could be super helpful https://code.google.com/p/psutil/

- these are dumped to a log file with data 'string-escape'd.

- http api for retrieving old data and logs
    /task/$jid
    /task/$jid/logs


API
===

from aque import current_task
current_task() -> proxies to the current task via threading.local()


Unsorted
========

- `aque` command-line to queue shell tasks
    - output specifies dependency for piping, e.g.:
        a=$(aque echo hello)
        b=$(aque --pipe-from "$a" md5)
        aque --wait --results "$b"

- tools to look at with significant startup overhead:
    - REDline
    - ARC_CMD (Arri debayering)
    - one of Jon's image processing scripts, e.g.:
        ~/dev/fidata/hk_dpx_jsrenderpull.py dpxrender_VFX_PULL_030_090913.js | xargs -L24 -P30 ~/dev/fidata/scaler/hk_render_jsdpx.py -j dpxrender_VFX_PULL_030_090913.js

- Python and bash APIs for fetching info about the current task. Communicated via environment variables.

    current_task().top_level.description
    current_task().set_status('suspend')

- reporting by timecodes and durations, instead of individual tasks. Then we can do an output status per sequence.
- ARC_CMD and others may stuff some metadata into the headers such as how many frames were processed in that sequence

- the only non-basic stuff that Jon wants is progress output for both UI updates (e.g. the web UI) and for knowing how far we got if it errored out

- Jon wants to make a modelling tool for each command that predicts what sort of output you will get and check that against what it actually does.

- hook onto Python logging

- Task.yield_() could allow the controller to pause its greenlet in case a higher priority job came in.


